{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e973c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # 匯入requests函式庫以便能夠在後續程式碼中執行http請求\n",
    "from bs4 import BeautifulSoup #從bs4函式庫匯入BeautifulSoup函式，用來解析網頁。\n",
    "\n",
    "#從range(1, 9)中每次提取一個y值，(即y=1, y=2, y=3...)。\n",
    "#將當下的y值透過str()將其強制轉換成字串形態，\n",
    "#並且透過replace()函式將url網址中的x替換成y的內容 (如 y='1' → x='1')，\n",
    "#每完成一次替換就會產生更新過的url，也就是將當下替換結果放到等號左邊的url變數存放。\n",
    "#由於每完成一次替換就會產生新的url，故以requests.get()再一次請求新網址的內容，\n",
    "#上述步驟完成後，將請求結果放到等號左邊的res變數存放。\n",
    "#接著透過BeautifulSoup解析當下的res，並且將解析結果放到等號左邊的soup變數存放。\n",
    "#從soup中選取所欲爬取的標簽名稱 (即.product_title a)，並且將此選取結果當作迴圈基底資料。\n",
    "#從迴圈基底資料中每次提取一筆tour_title，並且列印出文字與超連結部分。\n",
    "\n",
    "for y in range(1, 9): \n",
    "    url = \"https://vacations.ctrip.com/tours/d-xian-7/freetravel/px#_flta\"\n",
    "    url = url.replace('x', str(y))\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    for tour_title in soup.select('.product_title a'):\n",
    "        print(tour_title.text, \"\\n\", 'https:' + tour_title['href'].strip(\"?kwd=%e8%a5%bf%e5%ae%89\"), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3102a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # 匯入requests函式庫以便能夠在後續程式碼中執行http請求\n",
    "from bs4 import BeautifulSoup #從bs4函式庫匯入BeautifulSoup函式，用來解析網頁。\n",
    "\n",
    "res = requests.get(\"https://vacations.ctrip.com/tours/d-xian-7/freetravel/p1#_flta\")\n",
    "#以request函式庫內的get()函式來請求http網頁內容，其中括弧內通常傳入字串形態網址。\n",
    "#完成上述網頁內容請求之後，將結果放入等號左邊的res變數存放。\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "#透過BeautifulSoup()函式來解析請求回來的網頁內容，\n",
    "#其中括弧內第一個參數response.text是解析對像、第二個參數html.parser是解析模式。\n",
    "#完成網頁內容解析之後將其結果放入等號左邊的soup變數存放\n",
    "\n",
    "titles = soup.select('.product_title a')\n",
    "#藉由select()函式，從解析完成的soup中選取所欲爬取之標的物 (即.product_title a)。\n",
    "#並且將選取完成之標的放入等號左邊的titles變數存放\n",
    "\n",
    "for tour_title in titles:\n",
    "    print(tour_title.text, \"\\n\", 'https:' + tour_title['href'].strip(\"?kwd=%e8%a5%bf%e5%ae%89\"), \"\\n\")\n",
    "\n",
    "#透過for迴圈從titles所有資料中列印出每一筆tour_title資料，其中:\n",
    "# (1) print()內第一個參數 tour_title.text 表示僅列印tour_title中的文字內容\n",
    "# (2) print()內第二個參數 \"\\n\" 表示按下Enter鍵換行之意\n",
    "# (3) print()內第三個參數 'https:' 手動補上網址開頭 (因爬取回來的網址缺乏這部份)\n",
    "# (4) print()內第四個參數 + 表示串接符號，用來將其前後內容連結起來。\n",
    "# (5) print()內第五個參數 tour_title['href'].strip(\"?kwd=%e8%a5%bf%e5%ae%89\")\n",
    "#     表示僅列印tour_title中的超連結內容，並且將網址最末端的\n",
    "#     ?kwd=%e8%a5%bf%e5%ae%89冗餘內容，透過strip()函式予以去除。\n",
    "# (6) print()內第六個參數 \"\\n\" 表示按下Enter鍵換行之意\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
